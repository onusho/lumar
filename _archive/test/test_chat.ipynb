{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import DatabaseClient\n",
    "\n",
    "class RetrieverClient:\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.__database = DatabaseClient(folder_path)\n",
    "\n",
    "    def __retrieve(self, text=None, image_path=None):\n",
    "        if image_path == None and text == None:\n",
    "            return []\n",
    "        elif image_path != None and text != None:\n",
    "            return self.__database.search_with_image(image_path) + self.database.search_with_text(text)\n",
    "        elif text == None:\n",
    "            return self.__database.search_with_image(image_path)\n",
    "        elif image_path == None:\n",
    "            return self.__database.search_with_text(text)\n",
    "    \n",
    "    def __organize_by_media_type(self, properties):\n",
    "        response =  {\n",
    "            'text': [],\n",
    "            'image': []\n",
    "        }\n",
    "        for property in properties:\n",
    "            if property[\"media_type\"] == \"text\" and property not in response['text']:\n",
    "                response['text'].append(property)\n",
    "            if property[\"media_type\"] == \"image\" and property not in response['image']:\n",
    "                response.append(property)\n",
    "        return response\n",
    "    \n",
    "    def search(self, text=None, image_path=None):\n",
    "        return self.__organize_by_media_type(self.__retrieve(text, image_path))\n",
    "    \n",
    "    def close_database_connection(self):\n",
    "        self.__database.close_connection()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OfflineChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ollama\n",
    "\n",
    "# modelfile = \"\"\"FROM phi3\"\"\"\n",
    "# ollama.create(model=\"phi3\", modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "class OfflineChat:\n",
    "    \n",
    "    def __init__(self, model=\"phi3-rag\"):\n",
    "        self.__messages = []\n",
    "        self.__model = model\n",
    "    \n",
    "    def __append_user_message(self, user_query, search_result):\n",
    "        content = \"\"\n",
    "        image_paths = []\n",
    "        for text_properties in search_result['text']:\n",
    "            content += text_properties['text'] + \"\\n\"\n",
    "        for image_properties in search_result['image']:\n",
    "            image_paths.append(image_properties['path'])\n",
    "        query_with_context = f\"\"\"Given Context: {content}\n",
    "                                 Query: {user_query}\"\"\"\n",
    "        self.__messages.append({\"role\": \"user\", \"content\": query_with_context, \"images\": image_paths})\n",
    "    \n",
    "    def append_assistant_message(self, content):\n",
    "        self.__messages.append({\"role\": \"assistant\", \"content\" : content})  \n",
    "         \n",
    "    def get_assistant_response(self, user_text, search_result):\n",
    "        \"\"\"\n",
    "        Usage:\n",
    "            for chunk in get_assistant_response(...):\n",
    "                assistant_response += chunk[\"message\"][\"content\"]\n",
    "                print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "            offline_chat.append_assistant_message(assistant_response)\n",
    "        \"\"\"\n",
    "        self.__append_user_message(user_text, search_result)\n",
    "        return ollama.chat(self.__model, self.__messages, stream=True, options={\"temperature\":0})\n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.__messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnlineChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Image\n",
    "\n",
    "class OnlineChat:\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.__chat = self.__initiate_chat(api_key=api_key)\n",
    "         \n",
    "    def __initiate_chat(self, api_key, model_name=\"gemini-1.5-flash-001\"):\n",
    "        system_instructions = \"You are a RAG Chatbot and you will only respond using the information given to you and nothing else.\"\n",
    "        safey_settings = [\n",
    "            {\n",
    "                \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "                \"threshold\": \"BLOCK_NONE\",\n",
    "            },\n",
    "            {\n",
    "                \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "                \"threshold\": \"BLOCK_NONE\",\n",
    "            },\n",
    "            {\n",
    "                \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "                \"threshold\": \"BLOCK_NONE\",\n",
    "            },\n",
    "            {\n",
    "                \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "                \"threshold\": \"BLOCK_NONE\",\n",
    "            },\n",
    "        ]\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(model_name=model_name, \n",
    "                                      system_instruction=system_instructions, \n",
    "                                      safety_settings=safey_settings)\n",
    "        return model.start_chat()\n",
    "    \n",
    "    def __create_user_message(self, user_text, search_result):\n",
    "        content = \"\"\n",
    "        images = []\n",
    "        for text_properties in search_result['text']:\n",
    "            content += text_properties['text'] + \"\\n\"\n",
    "        for image_properties in search_result['image']:\n",
    "            images.append(Image(image_properties['path']))\n",
    "        query_with_context = [f\"Given Context: {content} \\nQuery: {user_text}\"] + images\n",
    "        return query_with_context\n",
    "    \n",
    "    def get_assistant_response(self, user_text, search_result):\n",
    "        \"\"\"\n",
    "        Usage:\n",
    "            chat = OnlineChat(...)\n",
    "            for chunk in chat.get_assistant_response(user_text, user_image_path):\n",
    "                print(chunk.text, end=\"\", flush=True)\n",
    "        \"\"\"\n",
    "        return self.__chat.send_message(content=self.__create_user_message(user_text, search_result), stream=True)    \n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.__chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat import OnlineChat, OfflineChat\n",
    "from retriever import RetrieverClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_offline_response(chat_client: OfflineChat, search_result, user_text=None):\n",
    "    assistant_response = \"\"\n",
    "    for chunk in chat_client.get_assistant_response(user_text=user_text, search_result=search_result):\n",
    "        assistant_response += chunk[\"message\"][\"content\"]\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "        chat_client.append_assistant_message(assistant_response)\n",
    "        \n",
    "def handle_online_response(chat_client : OnlineChat, search_result, user_text=None):\n",
    "    for chunk in chat_client.get_assistant_response(user_text=user_text, search_result=search_result):\n",
    "        print(chunk.text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\Anush\\Desktop\\Christ\\Specialization Project\\Localinsight\\documents\"\n",
    "mode = \"online\"\n",
    "api_key = \"\"\n",
    "\n",
    "user_query = \"Why did Alice leave?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = RetrieverClient(folder_path=folder_path)\n",
    "chat_client = OfflineChat() if mode == \"offline\" else OnlineChat(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = retriever.search(text=user_query, image_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [{'text': 'called out in a trembling voice to its children, “Come away, my dears! It’s high time you were all in bed!” On various pretexts they all moved off, and Alice was soon left alone.',\n",
       "   'chunk_no': 147.0,\n",
       "   'path': 'C:\\\\Users\\\\Anush\\\\Desktop\\\\Christ\\\\Specialization Project\\\\Localinsight\\\\text-only-test\\\\documents\\\\alice.txt',\n",
       "   'media_type': 'text'},\n",
       "  {'text': '“I wish I hadn’t mentioned Dinah!” she said to herself in a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and',\n",
       "   'media_type': 'text',\n",
       "   'path': 'C:\\\\Users\\\\Anush\\\\Desktop\\\\Christ\\\\Specialization Project\\\\Localinsight\\\\text-only-test\\\\documents\\\\alice.txt',\n",
       "   'chunk_no': 148.0},\n",
       "  {'text': '“Come, there’s no use in crying like that!” said Alice to herself, rather sharply; “I advise you to leave off this minute!” She generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she',\n",
       "   'media_type': 'text',\n",
       "   'path': 'C:\\\\Users\\\\Anush\\\\Desktop\\\\Christ\\\\Specialization Project\\\\Localinsight\\\\text-only-test\\\\documents\\\\alice.txt',\n",
       "   'chunk_no': 45.0},\n",
       "  {'text': 'In another moment down went Alice after it, never once considering how in the world she was to get out again.',\n",
       "   'media_type': 'text',\n",
       "   'path': 'C:\\\\Users\\\\Anush\\\\Desktop\\\\Christ\\\\Specialization Project\\\\Localinsight\\\\text-only-test\\\\documents\\\\alice.txt',\n",
       "   'chunk_no': 7.0},\n",
       "  {'text': 'Down, down, down. There was nothing else to do, so Alice soon began talking again. “Dinah’ll miss me very much to-night, I should think!” (Dinah was the cat.) “I hope they’ll remember her saucer of milk at tea-time. Dinah my dear! I wish you were down here with me! There are no mice in the air, I’m',\n",
       "   'media_type': 'text',\n",
       "   'path': 'C:\\\\Users\\\\Anush\\\\Desktop\\\\Christ\\\\Specialization Project\\\\Localinsight\\\\text-only-test\\\\documents\\\\alice.txt',\n",
       "   'chunk_no': 19.0}],\n",
       " 'image': []}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_offline_response(chat_client, search_result, user_query) if mode == \"offline\" \\\n",
    "else handle_online_response(chat_client, search_result, user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was left alone because her mother called her and her siblings to bed. \n"
     ]
    }
   ],
   "source": [
    "message_history = chat_client.get_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
