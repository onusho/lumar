{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: win32com is not available on non-Windows platforms. DOC file processing will be skipped.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from docx import Document \n",
    "import speech_recognition as sr\n",
    "import cv2\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, UnstructuredPowerPointLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, folder_path, chunk_size=100, chunk_overlap=10):\n",
    "        self.folder_path = folder_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def process_text_file(self, file_path):\n",
    "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        return [\n",
    "            {\n",
    "                \"chunk_no\": int(idx),\n",
    "                \"text\": chunk.page_content,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"text\",\n",
    "                \"media_type\": \"text\"\n",
    "            }\n",
    "            for idx, chunk in enumerate(chunks)\n",
    "        ]\n",
    "\n",
    "    def process_pdf_file(self, file_path):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size, \n",
    "            chunk_overlap=self.chunk_overlap\n",
    "            )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        return [\n",
    "            {\n",
    "                \"chunk_no\": int(idx),\n",
    "                \"text\": chunk.page_content,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"pdf\",\n",
    "                \"media_type\": \"text\"\n",
    "            }\n",
    "            for idx, chunk in enumerate(chunks)\n",
    "        ]\n",
    "\n",
    "    def process_pptx_file(self, file_path):\n",
    "        loader = UnstructuredPowerPointLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size, \n",
    "            chunk_overlap=self.chunk_overlap\n",
    "            )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        return [\n",
    "            {\n",
    "                \"chunk_no\": int(idx),\n",
    "                \"text\": chunk.page_content,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"pptx\",\n",
    "                \"media_type\": \"text\"\n",
    "            }\n",
    "            for idx, chunk in enumerate(chunks)\n",
    "        ]\n",
    "\n",
    "    def process_xlsx_file(self, file_path):\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        chunked_documents = []\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "            chunked_documents.append({\n",
    "                \"chunk_no\": 1,\n",
    "                \"text\": df.to_dict(),\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"table\",\n",
    "                \"media_type\": \"text\"\n",
    "            })\n",
    "        return chunked_documents\n",
    "\n",
    "    # def process_doc_file(self, file_path):\n",
    "    #      NOTE This requires pywin32 and Microsoft Word installed on Windows\n",
    "    #     try:\n",
    "    #         word = win32.Dispatch(\"Word.Application\")\n",
    "    #         doc = word.Documents.Open(file_path)\n",
    "    #         text = doc.Range().Text\n",
    "    #         doc.Close(False)\n",
    "    #         word.Quit()\n",
    "    #         text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #             chunk_size=self.chunk_size, \n",
    "    #             chunk_overlap=self.chunk_overlap\n",
    "    #             )\n",
    "    #         chunks = text_splitter.split_text(text)\n",
    "    #         return [\n",
    "    #             {\n",
    "    #                 \"chunk_no\": int(idx),\n",
    "    #                 \"text\": chunk,\n",
    "    #                 \"path\": file_path,\n",
    "    #                 \"file_type\": \"doc\",\n",
    "    #                 \"media_type\": \"text\"\n",
    "    #             }\n",
    "    #             for idx, chunk in enumerate(chunks)\n",
    "    #         ]\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error processing DOC file {file_path}: {e}\")\n",
    "    #         return None\n",
    "\n",
    "    def process_docx_file(self, file_path):\n",
    "        # NOTE: This requires python-docx installed\n",
    "        try:\n",
    "            doc = Document(file_path)\n",
    "            text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                separators=[\" \"], \n",
    "                chunk_size=self.chunk_size, \n",
    "                chunk_overlap=self.chunk_overlap\n",
    "                )\n",
    "            chunks = text_splitter.split_text(text)\n",
    "            return [\n",
    "                {\n",
    "                    \"chunk_no\": int(idx),\n",
    "                    \"text\": chunk,\n",
    "                    \"path\": file_path,\n",
    "                    \"file_type\": \"docx\",\n",
    "                    \"media_type\": \"text\"\n",
    "                }\n",
    "                for idx, chunk in enumerate(chunks)\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOCX file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_audio_file(self, file_path):\n",
    "        recognizer = sr.Recognizer()\n",
    "        try:\n",
    "            # Ensure the audio file is in a format SpeechRecognition can handle (e.g., WAV)\n",
    "            # If it's MP3, you might need pydub to convert it first or ensure ffmpeg is used.\n",
    "            # For simplicity, assuming .wav is given, or that sr can handle it.\n",
    "            # If using ffmpeg for audio extraction, it's often best to convert to .wav explicitly.\n",
    "            if os.path.splitext(file_path)[1].lower() == '.mp3':\n",
    "                # This part is optional, only if you want to handle MP3s directly with sr without prior conversion\n",
    "                # It would require pydub (pip install pydub)\n",
    "                # from pydub import AudioSegment\n",
    "                # audio = AudioSegment.from_mp3(file_path)\n",
    "                # temp_wav_path = file_path.replace('.mp3', '.wav')\n",
    "                # audio.export(temp_wav_path, format=\"wav\")\n",
    "                # actual_file_path = temp_wav_path\n",
    "                pass # For now, let's assume it's handled or pre-converted\n",
    "            else:\n",
    "                actual_file_path = file_path\n",
    "\n",
    "            with sr.AudioFile(actual_file_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_data) # Using Google Web Speech API for recognition\n",
    "            chunks = [text[i:i + self.chunk_size] for i in range(0, len(text), self.chunk_size)]\n",
    "\n",
    "            # if 'temp_wav_path' in locals() and os.path.exists(temp_wav_path):\n",
    "            #     os.remove(temp_wav_path) # Clean up temporary WAV if created\n",
    "\n",
    "            return [\n",
    "                {\n",
    "                    \"chunk_no\": int(idx),\n",
    "                    \"text\": chunk,\n",
    "                    \"path\": file_path,\n",
    "                    \"file_type\": \"audio\",\n",
    "                    \"media_type\": \"text\"\n",
    "                }\n",
    "                for idx, chunk in enumerate(chunks)\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio file {file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def process_image_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as image_file:\n",
    "                image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "            return [{\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"image\",\n",
    "                \"image\": image_base64,\n",
    "                \"media_type\": \"image\"\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_csv_file(self, file_path):\n",
    "        try:\n",
    "            csv_data = pd.read_csv(file_path).to_string()\n",
    "            return [{\n",
    "                \"chunk_no\": 1,\n",
    "                \"text\": csv_data,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"csv\",\n",
    "                \"media_type\": \"text\"\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing CSV file {file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def process_xml_file(self, file_path):\n",
    "        try:\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "            xml_data = ET.tostring(root, encoding='unicode')\n",
    "            return [{\n",
    "                \"chunk_no\": 1,\n",
    "                \"text\": xml_data,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"xml\",\n",
    "                \"media_type\": \"text\"\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing XML file {file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    def process_json_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                json_data = json.dumps(json.load(file), indent=4)\n",
    "            return [{\n",
    "                \"chunk_no\": 1,\n",
    "                \"text\": json_data,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"json\",\n",
    "                \"media_type\": \"text\"\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing JSON file {file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def process_video_file(self, file_path):\n",
    "        video_data = []\n",
    "        audio_path = file_path.replace(os.path.splitext(file_path)[1], \"_extracted_audio.wav\")\n",
    "\n",
    "        try:\n",
    "            # --- Extracting audio using ffmpeg-python ---\n",
    "            print(f\"Extracting audio from {file_path} to {audio_path}...\")\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(file_path)\n",
    "                .output(audio_path, acodec='pcm_s16le', ar='16000') # PCM 16-bit WAV, 16kHz sample rate\n",
    "                .run(overwrite_output=True, capture_stdout=True, capture_stderr=True)\n",
    "            )\n",
    "            print(\"Audio extraction complete. Processing audio...\")\n",
    "            audio_extracted_data = self.process_audio_file(audio_path)\n",
    "            if audio_extracted_data:\n",
    "                video_data.extend(audio_extracted_data)\n",
    "                print(f\"Added {len(audio_extracted_data)} audio chunks.\")\n",
    "            else:\n",
    "                print(\"No audio data extracted or processed.\")\n",
    "\n",
    "        except ffmpeg.Error as e:\n",
    "            print(f\"FFmpeg error extracting audio from {file_path}: {e.stderr.decode('utf8')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during audio extraction: {e}\")\n",
    "        finally:\n",
    "            if os.path.exists(audio_path):\n",
    "                os.remove(audio_path) # Clean up temporary audio file\n",
    "                print(f\"Cleaned up temporary audio file: {audio_path}\")\n",
    "\n",
    "        try:\n",
    "            # --- Extracting frames using OpenCV ---\n",
    "            print(f\"Extracting frames from {file_path} using OpenCV...\")\n",
    "            cap = cv2.VideoCapture(file_path)\n",
    "            if not cap.isOpened():\n",
    "                raise IOError(f\"Error: Could not open video file {file_path}\")\n",
    "\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            if fps == 0:\n",
    "                print(\"Warning: FPS is 0, cannot extract frames by interval. Extracting every Nth frame instead.\")\n",
    "                frames_to_skip = 30 # Default to every 30 frames if FPS is unknown\n",
    "            else:\n",
    "                frame_interval = 1 # seconds (same as original logic)\n",
    "                frames_to_skip = int(fps * frame_interval)\n",
    "                if frames_to_skip == 0: # Ensure at least 1 frame is skipped to avoid processing every frame\n",
    "                    frames_to_skip = 1\n",
    "\n",
    "            current_frame_idx = 0\n",
    "            extracted_frame_count = 0\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break # End of video\n",
    "\n",
    "                if current_frame_idx % frames_to_skip == 0:\n",
    "                    # Convert frame (NumPy array) to JPEG bytes\n",
    "                    # Use a higher quality for encoding, e.g., 90\n",
    "                    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "                    ret_encode, buffer = cv2.imencode('.jpg', frame, encode_param)\n",
    "                    if ret_encode:\n",
    "                        frame_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "                        video_data.append({\n",
    "                            \"chunk_no\": extracted_frame_count, # Use a separate counter for extracted frames\n",
    "                            \"image\": frame_base64,\n",
    "                            \"path\": file_path,\n",
    "                            \"file_type\": \"video_frame\",\n",
    "                            \"media_type\": \"image\"\n",
    "                        })\n",
    "                        extracted_frame_count += 1\n",
    "                current_frame_idx += 1\n",
    "\n",
    "            cap.release()\n",
    "            print(f\"Extracted {extracted_frame_count} video frames.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video frames from {file_path}: {e}\")\n",
    "            if 'cap' in locals() and cap.isOpened():\n",
    "                cap.release() # Ensure release even on error\n",
    "\n",
    "        return video_data\n",
    "\n",
    "    def process_file(self, file_path):\n",
    "        extension = os.path.splitext(file_path)[1].lower()\n",
    "        if extension == '.txt':\n",
    "            return self.process_text_file(file_path)\n",
    "        elif extension == '.pdf':\n",
    "            return self.process_pdf_file(file_path)\n",
    "        elif extension == '.pptx':\n",
    "            return self.process_pptx_file(file_path)\n",
    "        elif extension == '.xlsx':\n",
    "            return self.process_xlsx_file(file_path)\n",
    "        elif extension == '.doc':\n",
    "            return self.process_doc_file(file_path)\n",
    "        elif extension == '.docx':\n",
    "            return self.process_docx_file(file_path)\n",
    "        elif extension in ['.wav', '.mp3']: # Note: .mp3 might need pydub for speech_recognition\n",
    "            return self.process_audio_file(file_path)\n",
    "        elif extension in ['.png', '.jpg', '.jpeg', '.bmp', '.gif']:\n",
    "            return self.process_image_file(file_path)\n",
    "        elif extension in ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.mkv']: # Added more common video extensions\n",
    "            return self.process_video_file(file_path)\n",
    "        elif extension == '.csv':\n",
    "            return self.process_csv_file(file_path)\n",
    "        elif extension == '.xml':\n",
    "            return self.process_xml_file(file_path)\n",
    "        elif extension == '.json':\n",
    "            return self.process_json_file(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {extension} for file {file_path}\")\n",
    "            return None\n",
    "\n",
    "    def load_data(self):\n",
    "        all_data = []\n",
    "        for root, dirs, files in os.walk(self.folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "                processed_data = self.process_file(file_path)\n",
    "                if processed_data is not None:\n",
    "                    all_data.extend(processed_data)\n",
    "                else:\n",
    "                    print(f\"Skipping file due to processing error or unsupported type: {file_path}\")\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263f3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Multi2VecField\n",
    "from weaviate.classes.query import Filter\n",
    "import base64\n",
    "import os\n",
    "import re\n",
    "from hashlib import md5\n",
    "\n",
    "class DatabaseClient:\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.__folder_path = folder_path\n",
    "        self.__create_client()\n",
    "        if self.__generate_collection():\n",
    "            self.loader = DataLoader(folder_path, chunk_size=300, chunk_overlap=50)\n",
    "            self.__data_ingestion(folder_path)\n",
    "   \n",
    "    def __create_client(self):\n",
    "        self.client = weaviate.connect_to_local(port=8081)\n",
    "        # self.client = weaviate.Client(\n",
    "        #         url=\"http://localhost:8081\"  # host port, not container port\n",
    "        #     )\n",
    "    \n",
    "    # def __get_hashed_path(self):\n",
    "    #     return self.__folder_path.split(\"\\\\\")[-1]  + ''.join(filter(str.isalpha, md5(self.__folder_path.encode()).hexdigest()))\n",
    "\n",
    "    def __get_hashed_path(self):\n",
    "        folder_name = os.path.basename(self.__folder_path)\n",
    "        sanitized_name = re.sub(r'[^A-Za-z0-9_]', '', folder_name)\n",
    "        if not sanitized_name or not sanitized_name[0].isalpha() or not sanitized_name[0].isupper():\n",
    "            sanitized_name = \"Doc\" + sanitized_name.capitalize()\n",
    "        hash_suffix = ''.join(filter(str.isalnum, md5(self.__folder_path.encode()).hexdigest()))[:6]\n",
    "        class_name = f\"{sanitized_name}_{hash_suffix}\"\n",
    "        return class_name\n",
    "\n",
    "\n",
    "    def __generate_collection(self):\n",
    "        collection_name = self.__get_hashed_path()\n",
    "        if self.client.collections.exists(collection_name):\n",
    "            self.collection = self.client.collections.get(self.__get_hashed_path())\n",
    "            return False\n",
    "            # self.client.collections.delete(collection_name)\n",
    "\n",
    "        self.collection = self.client.collections.create(\n",
    "            name = self.__get_hashed_path(),\n",
    "            vectorizer_config=Configure.Vectorizer.multi2vec_clip(\n",
    "                    image_fields=[\n",
    "                        Multi2VecField(\n",
    "                            name=\"image\"\n",
    "                        )\n",
    "                    ],\n",
    "                    text_fields=[\n",
    "                        Multi2VecField(\n",
    "                            name=\"text\"\n",
    "                        ),\n",
    "                        Multi2VecField(\n",
    "                            name=\"path\"\n",
    "                        )\n",
    "                    ]\n",
    "            )\n",
    "        )\n",
    "        return True\n",
    "    \n",
    "    def __data_ingestion(self, folder_path):\n",
    "        object_list = self.loader.load_data()\n",
    "        with self.collection.batch.dynamic() as batch:\n",
    "            for object in object_list:\n",
    "                batch.add_object(\n",
    "                    properties=object\n",
    "                )\n",
    "    \n",
    "    def search_with_text(self, query : str, search_for=\"all\", limit=5):\n",
    "        if search_for == \"all\":\n",
    "            response =  self.collection.query.near_text(\n",
    "                query=query,\n",
    "                limit=limit\n",
    "            )\n",
    "        else:\n",
    "            response = self.collection.query.near_text(\n",
    "                query=query,\n",
    "                filters=Filter.by_property(\"media_type\").equal(search_for),\n",
    "                limit=limit\n",
    "            )\n",
    "        return [object.properties for object in response.objects]\n",
    "    \n",
    "    def __to_base64(self, path):\n",
    "            with open(path, 'rb') as file:\n",
    "                return base64.b64encode(file.read()).decode('utf-8')\n",
    "            \n",
    "    def search_with_image(self, image_path, search_for = 'all', limit=5):\n",
    "        if search_for == \"all\":\n",
    "            response = self.collection.query.near_image(\n",
    "                near_image=self.__to_base64(image_path),\n",
    "                limit=limit\n",
    "            )\n",
    "        else:\n",
    "            response = self.collection.query.near_image(\n",
    "                near_image=self.__to_base64(image_path),\n",
    "                filters=Filter.by_property(\"media_type\").equal(search_for),\n",
    "                limit=limit\n",
    "                )\n",
    "        return [object.properties for object in response.objects]\n",
    "\n",
    "    def list_collections(self):\n",
    "        return self.client.collections.list_all()\n",
    "    \n",
    "    def delete_collections(self, name):\n",
    "        return self.client.collections.delete(name)\n",
    "    \n",
    "    def close_connection(self):\n",
    "        self.client.close()\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"Folder: {self.__folder_path}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverClient:\n",
    "    def __init__(self, folder_path):\n",
    "        self.__database = DatabaseClient(folder_path)\n",
    "\n",
    "    def __retrieve(self, text=None, image_path=None, search_for=\"all\", limit=5):\n",
    "        if image_path == None and text == None:\n",
    "            return []\n",
    "        elif image_path != None and text != None:\n",
    "            return self.__database.search_with_image(image_path, search_for=search_for, limit=limit) + self.__database.search_with_text(text, search_for=search_for, limit=limit)\n",
    "        elif text == None:\n",
    "            return self.__database.search_with_image(image_path, search_for=search_for, limit=limit)\n",
    "        elif image_path == None:\n",
    "            return self.__database.search_with_text(text, search_for=search_for, limit=limit)\n",
    "    \n",
    "    def __organize_by_media_type(self, properties):\n",
    "        response =  {\n",
    "            'text': [],\n",
    "            'image': []\n",
    "        }\n",
    "        for property in properties:\n",
    "            if property[\"media_type\"] == \"text\" and property not in response['text']:\n",
    "                response['text'].append(property)\n",
    "            if property[\"media_type\"] == \"image\" and property not in response['image']:\n",
    "                response[\"image\"].append(property)\n",
    "        return response\n",
    "    \n",
    "    def search(self, text=None, image_path=None, search_for=\"all\", limit=5):\n",
    "        \"\"\"\n",
    "            Inputs: text and/or images\n",
    "            Options: search_for [all, text, image (name it media in frontend)], \n",
    "                    limit\n",
    "            Output: {\"text\":[],\n",
    "                    \"image\":[]}   \n",
    "                it's a dictionary with \"text\" and \"images\" fields which are lists\n",
    "        \"\"\"\n",
    "        return self.__organize_by_media_type(self.__retrieve(text, image_path, search_for=search_for, limit=limit))\n",
    "        \n",
    "    def close_database_connection(self):\n",
    "        self.__database.close_connection()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import speech_recognition as sr\n",
    "\n",
    "class Chat:\n",
    "    \n",
    "    def __init__(self, model=\"gemma3:latest\"):\n",
    "        self.__messages = []\n",
    "        self.__model = model\n",
    "    \n",
    "    def __process_audio_file(self, file_path):\n",
    "        recognizer = sr.Recognizer()\n",
    "        try:\n",
    "            with sr.AudioFile(file_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                return recognizer.recognize_google(audio_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio file {file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def __append_user_message(self, user_query=None, user_image_paths=None, user_audio_path=None):\n",
    "        audio_content = \"\"\n",
    "        image_paths = []\n",
    "        if user_query is None:\n",
    "            user_query = \"Describe.\"\n",
    "        if user_image_path:\n",
    "            image_paths.append(user_image_path)\n",
    "        if user_audio_path:\n",
    "            audio_content = self.__process_audio_file(user_audio_path)\n",
    "   \n",
    "        query_with_context = f\"\"\"Given Context: {audio_content}\n",
    "                                 Query: {user_query}\"\"\"\n",
    "        self.__messages.append({\"role\": \"user\", \"content\": query_with_context, \"images\": image_paths})\n",
    "\n",
    "    def append_assistant_message(self, content):\n",
    "        self.__messages.append({\"role\": \"assistant\", \"content\" : content})  \n",
    "    \n",
    "    def get_assistant_response(self, user_text=None, user_image_path=None, user_audio_path=None):\n",
    "        self.__append_user_message(user_text, user_image_path, user_audio_path)\n",
    "        return ollama.chat(self.__model, self.__messages, options={\"temperature\":0})\n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.__messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ea1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = RetrieverClient('/Users/anushverma/Desktop/lumar/_archive/documents')\n",
    "chat = Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372cdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when user adds \n",
    "response = chat.get_assistant_response(user_image_path='/Users/anushverma/Desktop/lumar/_archive/documents/cat3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78f80830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gemma3:latest',\n",
       " 'created_at': '2025-05-23T11:56:12.747742Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 27605313166,\n",
       " 'load_duration': 60969708,\n",
       " 'prompt_eval_count': 291,\n",
       " 'prompt_eval_duration': 24229854167,\n",
       " 'eval_count': 126,\n",
       " 'eval_duration': 3278491333,\n",
       " 'message': Message(role='assistant', content=\"Here's a description of the image:\\n\\nThe image shows a beautiful, fluffy, grey British Shorthair cat. It's a classic British Shorthair with a dense, plush coat in shades of grey. The cat has striking amber-colored eyes and a dignified expression. \\n\\nIt's wearing a miniature, ornate golden crown adorned with glittering jewels. A red and black feathered ribbon is tied around its neck. The background is a dark, solid black, which makes the cat and its crown stand out dramatically. The overall effect is regal and humorous, portraying the cat as a miniature king or queen.\", images=None, tool_calls=None)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b9896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
