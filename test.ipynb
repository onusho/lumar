{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edba807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import base64\n",
    "import speech_recognition as sr\n",
    "from moviepy import VideoFileClip\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, UnstructuredPowerPointLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, folder_path, chunk_size=100, chunk_overlap=10):\n",
    "        self.folder_path = folder_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def process_text_file(self, file_path):\n",
    "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        return [\n",
    "            {\n",
    "                \"chunk_no\": int(idx),\n",
    "                \"text\": chunk.page_content,\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"text\",\n",
    "                \"media_type\": \"text\"\n",
    "            }\n",
    "            for idx, chunk in enumerate(chunks)\n",
    "        ]\n",
    "\n",
    "    def process_image_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as image_file:\n",
    "                image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "            return [{\n",
    "                \"path\": file_path,\n",
    "                \"file_type\": \"image\",\n",
    "                \"image\": image_base64,\n",
    "                \"media_type\": \"image\"\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_audio_file(self, file_path):\n",
    "        recognizer = sr.Recognizer()\n",
    "        try:\n",
    "            with sr.AudioFile(file_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "            chunks = [text[i:i + self.chunk_size] for i in range(0, len(text), self.chunk_size)]\n",
    "\n",
    "            return [\n",
    "                {\n",
    "                    \"chunk_no\": int(idx),\n",
    "                    \"text\": chunk,\n",
    "                    \"path\": file_path,\n",
    "                    \"file_type\": \"audio\",\n",
    "                    \"media_type\": \"text\"\n",
    "                }\n",
    "                for idx, chunk in enumerate(chunks)\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio file {file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_video_file(self, file_path, frame_interval=5, compression_quality=50, resize_factor=0.7):\n",
    "        \"\"\"\n",
    "        Processes a video file to extract audio and frames.\n",
    "        \n",
    "        Parameters:\n",
    "        - file_path (str): Path to the video file.\n",
    "        - frame_interval (int): Interval in seconds between frames to extract.\n",
    "        - compression_quality (int): Quality of the compressed image (1-100).\n",
    "        - resize_factor (float): Scaling factor for resizing images (0 < resize_factor <= 1).\n",
    "\n",
    "        Returns:\n",
    "        - list: A list of dictionaries containing audio data and frame data.\n",
    "        \"\"\"\n",
    "        video_data = []\n",
    "\n",
    "        # Ensure frame_interval is greater than 0 to avoid division by zero\n",
    "        if frame_interval <= 0:\n",
    "            print(f\"Error: frame_interval must be greater than 0. Received frame_interval={frame_interval}.\")\n",
    "            return video_data\n",
    "\n",
    "        try:\n",
    "            # Extracting audio\n",
    "            video = VideoFileClip(file_path)\n",
    "            audio_path = file_path.replace(os.path.splitext(file_path)[1], \".wav\")\n",
    "            \n",
    "            try:\n",
    "                video.audio.write_audiofile(audio_path)\n",
    "                audio_data = self.process_audio_file(audio_path)\n",
    "                if audio_data:\n",
    "                    video_data.extend(audio_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing audio file {audio_path}: {e}\")\n",
    "\n",
    "            # Extracting frames\n",
    "            for i, frame in enumerate(video.iter_frames(fps=1.0 / frame_interval)):\n",
    "                # Convert frame (numpy array) to PIL image\n",
    "                pil_image = Image.fromarray(frame)\n",
    "                \n",
    "                # Resize the image if resize_factor is less than 1\n",
    "                if resize_factor < 1.0:\n",
    "                    new_size = (int(pil_image.width * resize_factor), int(pil_image.height * resize_factor))\n",
    "                    pil_image = pil_image.resize(new_size, Image.LANCZOS)\n",
    "                \n",
    "                # Compress the image\n",
    "                buffered = io.BytesIO()\n",
    "                pil_image.save(buffered, format=\"JPEG\", quality=compression_quality)\n",
    "                \n",
    "                # Convert to base64\n",
    "                frame_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "                \n",
    "                # Add frame data to video_data list\n",
    "                video_data.append({\n",
    "                    \"chunk_no\": i,\n",
    "                    \"image\": frame_base64,\n",
    "                    \"path\": file_path,\n",
    "                    \"file_type\": \"video_frame\",\n",
    "                    \"media_type\": \"image\"\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video file {file_path}: {e}\")\n",
    "        \n",
    "        return video_data\n",
    "\n",
    "    \n",
    "    def process_file(self, file_path):\n",
    "        extension = os.path.splitext(file_path)[1].lower()\n",
    "        if extension == '.txt':\n",
    "            return self.process_text_file(file_path)\n",
    "        elif extension in ['.wav', '.mp3']:\n",
    "            return self.process_audio_file(file_path)\n",
    "        elif extension in ['.png', '.jpg', '.jpeg', '.bmp', '.gif', 'jfif']:\n",
    "            return self.process_image_file(file_path)\n",
    "        elif extension in ['.mp4', '.avi', '.mov', '.wmv']:\n",
    "            return self.process_video_file(file_path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def load_data(self):\n",
    "        all_data = []\n",
    "        for root, dirs, files in os.walk(self.folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                processed_data = self.process_file(file_path)\n",
    "                if processed_data is not None:\n",
    "                    all_data.extend(processed_data)\n",
    "        return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45182d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy\n",
    "# !pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d699c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import DataLoader\n",
    "\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Multi2VecField\n",
    "from weaviate.classes.query import Filter\n",
    "import base64\n",
    "import os\n",
    "import re\n",
    "from hashlib import md5\n",
    "\n",
    "class DatabaseClient:\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.__folder_path = folder_path\n",
    "        self.__create_client()\n",
    "        if self.__generate_collection():\n",
    "            self.loader = DataLoader(folder_path, chunk_size=300, chunk_overlap=50)\n",
    "            self.__data_ingestion(folder_path)\n",
    "   \n",
    "    def __create_client(self):\n",
    "        self.client = weaviate.connect_to_local(port=8081)\n",
    "        # self.client = weaviate.Client(\n",
    "        #         url=\"http://localhost:8081\"  # host port, not container port\n",
    "        #     )\n",
    "    \n",
    "    # def __get_hashed_path(self):\n",
    "    #     return self.__folder_path.split(\"\\\\\")[-1]  + ''.join(filter(str.isalpha, md5(self.__folder_path.encode()).hexdigest()))\n",
    "\n",
    "    def __get_hashed_path(self):\n",
    "        folder_name = os.path.basename(self.__folder_path)\n",
    "        sanitized_name = re.sub(r'[^A-Za-z0-9_]', '', folder_name)\n",
    "        if not sanitized_name or not sanitized_name[0].isalpha() or not sanitized_name[0].isupper():\n",
    "            sanitized_name = \"Doc\" + sanitized_name.capitalize()\n",
    "        hash_suffix = ''.join(filter(str.isalnum, md5(self.__folder_path.encode()).hexdigest()))[:6]\n",
    "        class_name = f\"{sanitized_name}_{hash_suffix}\"\n",
    "        return class_name\n",
    "\n",
    "\n",
    "    def __generate_collection(self):\n",
    "        collection_name = self.__get_hashed_path()\n",
    "        if self.client.collections.exists(collection_name):\n",
    "            self.collection = self.client.collections.get(self.__get_hashed_path())\n",
    "            return False\n",
    "            # self.client.collections.delete(collection_name)\n",
    "\n",
    "        self.collection = self.client.collections.create(\n",
    "            name = self.__get_hashed_path(),\n",
    "            vectorizer_config=Configure.Vectorizer.multi2vec_clip(\n",
    "                    image_fields=[\n",
    "                        Multi2VecField(\n",
    "                            name=\"image\"\n",
    "                        )\n",
    "                    ],\n",
    "                    text_fields=[\n",
    "                        Multi2VecField(\n",
    "                            name=\"text\"\n",
    "                        ),\n",
    "                        Multi2VecField(\n",
    "                            name=\"path\"\n",
    "                        )\n",
    "                    ]\n",
    "            )\n",
    "        )\n",
    "        return True\n",
    "    \n",
    "    def __data_ingestion(self, folder_path):\n",
    "        object_list = self.loader.load_data()\n",
    "        with self.collection.batch.dynamic() as batch:\n",
    "            for object in object_list:\n",
    "                batch.add_object(\n",
    "                    properties=object\n",
    "                )\n",
    "    \n",
    "    def search_with_text(self, query : str, search_for=\"all\", limit=5):\n",
    "        if search_for == \"all\":\n",
    "            response =  self.collection.query.near_text(\n",
    "                query=query,\n",
    "                limit=limit\n",
    "            )\n",
    "        else:\n",
    "            response = self.collection.query.near_text(\n",
    "                query=query,\n",
    "                filters=Filter.by_property(\"media_type\").equal(search_for),\n",
    "                limit=limit\n",
    "            )\n",
    "        return [object.properties for object in response.objects]\n",
    "    \n",
    "    def __to_base64(self, path):\n",
    "            with open(path, 'rb') as file:\n",
    "                return base64.b64encode(file.read()).decode('utf-8')\n",
    "            \n",
    "    def search_with_image(self, image_path, search_for = 'all', limit=5):\n",
    "        if search_for == \"all\":\n",
    "            response = self.collection.query.near_image(\n",
    "                near_image=self.__to_base64(image_path),\n",
    "                limit=limit\n",
    "            )\n",
    "        else:\n",
    "            response = self.collection.query.near_image(\n",
    "                near_image=self.__to_base64(image_path),\n",
    "                filters=Filter.by_property(\"media_type\").equal(search_for),\n",
    "                limit=limit\n",
    "                )\n",
    "        return [object.properties for object in response.objects]\n",
    "\n",
    "    def list_collections(self):\n",
    "        return self.client.collections.list_all()\n",
    "    \n",
    "    def delete_collections(self, name):\n",
    "        return self.client.collections.delete(name)\n",
    "    \n",
    "    def close_connection(self):\n",
    "        self.client.close()\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"Folder: {self.__folder_path}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0b8516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Folder: /Users/anushverma/Desktop/lumar/_archive/documents"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatabaseClient('/Users/anushverma/Desktop/lumar/_archive/documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a934cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import speech_recognition as sr\n",
    "\n",
    "class Chat:\n",
    "    \n",
    "    def __init__(self, model=\"llama3.2-vision\"):\n",
    "        self.__messages = []\n",
    "        self.__model = model\n",
    "    \n",
    "    def __process_audio_file(self, file_path):\n",
    "        recognizer = sr.Recognizer()\n",
    "        try:\n",
    "            with sr.AudioFile(file_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                return recognizer.recognize_google(audio_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio file {file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def __append_user_message(self, user_query, user_image_path, user_audio_path):\n",
    "        audio_content = \"\"\n",
    "        image_paths = []\n",
    "        if user_query is None:\n",
    "            user_query = \"Describe.\"\n",
    "        if user_image_path:\n",
    "            image_paths.append(user_image_path)\n",
    "        if user_audio_path:\n",
    "            audio_content = self.__process_audio_file(user_audio_path)\n",
    "   \n",
    "        query_with_context = f\"\"\"Given Context: {audio_content}\n",
    "                                 Query: {user_query}\"\"\"\n",
    "        self.__messages.append({\"role\": \"user\", \"content\": query_with_context, \"images\": image_paths})\n",
    "\n",
    "    def append_assistant_message(self, content):\n",
    "        self.__messages.append({\"role\": \"assistant\", \"content\" : content})  \n",
    "    \n",
    "    def get_assistant_response(self, user_text=None, user_image_path=None, user_audio_path=None):\n",
    "        self.__append_user_message(user_text, user_image_path, user_audio_path)\n",
    "        return ollama.chat(self.__model, self.__messages, options={\"temperature\":0})\n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.__messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f0f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports \n",
    "# import os\n",
    "# import json\n",
    "# import hashlib\n",
    "# import base64\n",
    "# import time\n",
    "# import streamlit as st\n",
    "# from chat import Chat\n",
    "# from retriever import RetrieverClient \n",
    "\n",
    "# # Session State Initializations\n",
    "# if 'folder_path' not in st.session_state:\n",
    "#     st.session_state['folder_path'] = None\n",
    "# if 'indexing_done' not in st.session_state:\n",
    "#     st.session_state['indexing_done'] = False\n",
    "# if 'main_mode' not in st.session_state:\n",
    "#     st.session_state['main_mode'] = 'Chat'\n",
    "# if 'chat_mode' not in st.session_state:\n",
    "#     st.session_state['chat_mode'] = 'offline'\n",
    "# if 'chat_messages' not in st.session_state:\n",
    "#     st.session_state['chat_messages'] = []\n",
    "# if 'search_messages' not in st.session_state:\n",
    "#     st.session_state['search_messages'] = []\n",
    "# if 'logged_in' not in st.session_state:\n",
    "#     st.session_state['logged_in'] = False\n",
    "# if 'change_folder_mode' not in st.session_state:\n",
    "#     st.session_state['change_folder_mode'] = False\n",
    "# if 'retriever' not in st.session_state:\n",
    "#     st.session_state['retriever'] = None\n",
    "# if 'chat' not in st.session_state:\n",
    "#     st.session_state['chat'] = None\n",
    "\n",
    "# CREDENTIALS_FILE = \"user_credentials.json\"\n",
    "\n",
    "# # Password Hash Function\n",
    "# def hash_password(password):\n",
    "#     return hashlib.sha256(password.encode()).hexdigest()\n",
    "\n",
    "# # Parse Json File to load credentials\n",
    "# def load_credentials():\n",
    "#     if os.path.exists(CREDENTIALS_FILE):\n",
    "#         with open(CREDENTIALS_FILE, 'r') as file:\n",
    "#             try:\n",
    "#                 return json.load(file)\n",
    "#             except json.JSONDecodeError:\n",
    "#                 return {}\n",
    "#     return {}\n",
    "\n",
    "# # Save Provided credentials back into the Json file\n",
    "# def save_credentials(credentials):\n",
    "#     with open(CREDENTIALS_FILE, 'w') as file:\n",
    "#         json.dump(credentials, file)\n",
    "\n",
    "# # Login Function\n",
    "# def login(username, password):\n",
    "#     credentials = load_credentials()\n",
    "#     hashed_password = hash_password(password)\n",
    "#     if username in credentials and credentials[username]['password'] == hashed_password:\n",
    "#         st.session_state['logged_in'] = True\n",
    "#         st.session_state['username'] = username\n",
    "#         st.session_state['folder_path'] = credentials[username]['folder_path']\n",
    "#         initialize_clients(st.session_state['folder_path'])\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "# # Signup Function\n",
    "# def signup(username, password, folder_path):\n",
    "#     credentials = load_credentials()\n",
    "#     if username not in credentials:\n",
    "#         hashed_password = hash_password(password)\n",
    "#         credentials[username] = {'password': hashed_password, 'folder_path': folder_path}\n",
    "#         save_credentials(credentials)\n",
    "#         st.session_state['logged_in'] = True\n",
    "#         st.session_state['username'] = username\n",
    "#         st.session_state['folder_path'] = folder_path\n",
    "#         initialize_clients(folder_path)\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "# # Logout Function\n",
    "# def logout():\n",
    "#     st.session_state.clear()\n",
    "#     st.session_state['logged_in'] = False\n",
    "\n",
    "# # UI for Login/Signup\n",
    "# def login_signup_interface():\n",
    "#     st.title(\"LocalInsight - Document Search and Chat\")\n",
    "#     st.write(\"Welcome to LocalInsight, your personal document assistant!\")  \n",
    "#     login_tab, signup_tab = st.tabs([\"Login\", \"Signup\"])   \n",
    "#     with login_tab:\n",
    "#         username = st.text_input(\"Username\", key=\"login_username\")\n",
    "#         password = st.text_input(\"Password\", type=\"password\", key=\"login_password\")\n",
    "#         if st.button(\"Login\", key=\"login_button\"):\n",
    "#             if login(username, password):\n",
    "#                 st.success(\"Logged in successfully!\")\n",
    "#                 st.rerun()\n",
    "#             else:\n",
    "#                 st.error(\"Invalid username or password.\")\n",
    "#     with signup_tab:\n",
    "#         new_username = st.text_input(\"New Username\", key=\"signup_username\")\n",
    "#         new_password = st.text_input(\"New Password\", type=\"password\", key=\"signup_password\")\n",
    "#         folder_path = st.text_input(\"Initial Folder Path\", key=\"signup_folder_path\")\n",
    "#         if st.button(\"Signup\", key=\"signup_button\"):\n",
    "#             if signup(new_username, new_password, folder_path):\n",
    "#                 st.success(\"Signed up and logged in successfully!\")\n",
    "#                 st.session_state['indexing_done'] = False\n",
    "#                 st.rerun()\n",
    "#             else:\n",
    "#                 st.error(\"Username already exists.\")\n",
    "\n",
    "# # Lets user change document directory\n",
    "# def set_folder_path():\n",
    "#     st.header(\"Change Folder Path\")\n",
    "#     folder_path = st.text_input(\"Enter the folder path to index:\", key=\"folder_path_input\")\n",
    "#     if folder_path:\n",
    "#         if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "#             st.session_state['folder_path'] = folder_path\n",
    "#             update_folder_path(st.session_state['username'], folder_path)\n",
    "#             initialize_clients(folder_path)\n",
    "#             st.session_state['indexing_done'] = True\n",
    "#             st.session_state['change_folder_mode'] = False\n",
    "#             st.success(\"Folder path updated successfully!\")\n",
    "#             st.rerun()\n",
    "#         else:\n",
    "#             st.error(\"Invalid folder path. Please enter a valid path.\")\n",
    "#     if st.button(\"Back\"):\n",
    "#         st.session_state['change_folder_mode'] = False\n",
    "#         st.rerun()\n",
    "\n",
    "# # Overwrite changed folder path content into the json file\n",
    "# def update_folder_path(username, folder_path):\n",
    "#     credentials = load_credentials()\n",
    "#     if username in credentials:\n",
    "#         credentials[username]['folder_path'] = folder_path\n",
    "#         save_credentials(credentials)\n",
    "\n",
    "# # Initialize Retriever & Chat Clients\n",
    "# def initialize_clients(folder_path):\n",
    "#     st.session_state['retriever'] = RetrieverClient(folder_path)\n",
    "#     st.session_state['chat'] = Chat()\n",
    "\n",
    "\n",
    "# def handle_chat():\n",
    "#     # # Display past chat messages\n",
    "#     # for message in st.session_state['chat_messages']:\n",
    "#     #     if message['role'] == 'user':\n",
    "#     #         with st.chat_message(\"user\"):\n",
    "#     #             st.write(message['content'])\n",
    "#     #     else:\n",
    "#     #         with st.chat_message(\"assistant\"):\n",
    "#     #             st.write(message['content'])\n",
    "\n",
    "#     # Input fields for user message, audio, and image\n",
    "#     user_message = st.chat_input(\"Type your message here:\")\n",
    "#     user_audio = st.file_uploader(\"Or upload an audio file:\", type=[\"wav\", \"mp3\"], key=\"audio_uploader\")\n",
    "#     # user_audio = None\n",
    "#     user_image = st.file_uploader(\"Or upload an image:\", type=[\"png\", \"jpg\", \"jpeg\"], key=\"image_uploader\")\n",
    "\n",
    "#     # When a message or file is uploaded\n",
    "#     if user_message or user_audio or user_image:\n",
    "#         user_query = user_message if user_message else None\n",
    "\n",
    "#         user_audio_path = None\n",
    "#         user_image_path = None\n",
    "\n",
    "#         # Save uploaded image or audio to temporary path\n",
    "#         if user_image:\n",
    "#             user_image_path = f\"temp_uploaded_image.{user_image.name.split('.')[-1]}\"\n",
    "#             with open(user_image_path, \"wb\") as f:\n",
    "#                 f.write(user_image.getbuffer())\n",
    "\n",
    "#         if user_audio:\n",
    "#             user_audio_path = f\"temp_uploaded_audio.{user_audio.name.split('.')[-1]}\"\n",
    "#             with open(user_audio_path, \"wb\") as f:\n",
    "#                 f.write(user_audio.getbuffer())\n",
    "\n",
    "#         chat_client = st.session_state['chat']\n",
    "\n",
    "#         # Get response from assistant and append user message to chat history\n",
    "#         response = chat_client.get_assistant_response(\n",
    "#             user_text=user_query,\n",
    "#             user_image_path=user_image_path,\n",
    "#             user_audio_path=user_audio_path\n",
    "#         )\n",
    "\n",
    "#         # Extract assistant's response content\n",
    "#         assistant_response = response.message.content\n",
    "\n",
    "#         # Append user and assistant messages to chat history\n",
    "#         st.session_state['chat_messages'].append({\"role\": \"user\", \"content\": user_query or \"\"})\n",
    "#         st.session_state['chat_messages'].append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "#         # Display assistant's response\n",
    "#         with st.chat_message(\"assistant\"):\n",
    "#             st.write(assistant_response)\n",
    "\n",
    "#         # Clean up temporary files if uploaded\n",
    "#         if user_image_path and os.path.exists(user_image_path):\n",
    "#             os.remove(user_image_path)\n",
    "#         if user_audio_path and os.path.exists(user_audio_path):\n",
    "#             os.remove(user_audio_path)\n",
    "\n",
    "#     # Button to view chat history\n",
    "#     if st.button(\"View Chat History\"):\n",
    "#         st.write(\"### Chat History:\")\n",
    "#         for message in st.session_state['chat_messages']:\n",
    "#             role = \"User\" if message['role'] == \"user\" else \"Assistant\"\n",
    "#             st.write(f\"**{role}:** {message['content']}\")\n",
    "\n",
    "\n",
    "# # File Open Function\n",
    "# def open_file(path):\n",
    "#     try:\n",
    "#         if not os.path.exists(path):\n",
    "#             st.error(f\"File not found: {path}\")\n",
    "#             return\n",
    "#         # Open File in different applications\n",
    "#         if os.name == 'nt':  # For Windows\n",
    "#             os.startfile(path)\n",
    "#         elif os.name == 'posix':  # For macOS and Linux\n",
    "#             os.system(f'open \"{path}\"' if 'darwin' in os.uname().sysname.lower() else f'xdg-open \"{path}\"')\n",
    "#         else:\n",
    "#             st.warning(\"Your operating system may not support this operation.\")\n",
    "#     except Exception as e:\n",
    "#         st.error(f\"Failed to open the file: {e}\")\n",
    "\n",
    "# # Search Interaction Handler Function\n",
    "# import os\n",
    "# import streamlit as st\n",
    "\n",
    "# def handle_search():\n",
    "#     # Search input fields\n",
    "#     user_query = st.text_input(\"Type your search query here:\", key=\"search_input\")\n",
    "#     uploaded_image = st.file_uploader(\"Upload an image:\", type=[\"png\", \"jpg\", \"jpeg\"], key=\"image_uploader\")\n",
    "#     search_option = st.radio(\"Choose a search type:\", (\"Any\",\"Text\", \"Media\"))\n",
    "#     limit = st.slider(\"Number of Results\", min_value=1, max_value=20, value=5, key=\"limit_slider\")\n",
    "\n",
    "#     # Perform search when the search button is clicked\n",
    "#     if st.button(\"Search\", key=\"search_send\"):\n",
    "#         with st.spinner(\"Searching...\"):\n",
    "#             if user_query or uploaded_image:\n",
    "#                 image_path = None\n",
    "                \n",
    "#                 if uploaded_image:\n",
    "#                     image_path = f\"temp_uploaded_image.{uploaded_image.name.split('.')[-1]}\"\n",
    "#                     with open(image_path, \"wb\") as f:\n",
    "#                         f.write(uploaded_image.getbuffer())\n",
    "                        \n",
    "#                 if search_option == \"Any\": search_for = \"all\"\n",
    "#                 elif search_option == \"Text\": search_for = \"text\"\n",
    "#                 elif search_option == \"Media\": search_for = \"image\"\n",
    "\n",
    "#                 search_results = st.session_state['retriever'].search(\n",
    "#                     text=user_query, \n",
    "#                     image_path=image_path, \n",
    "#                     search_for=search_for, \n",
    "#                     limit=limit\n",
    "#                 )\n",
    "\n",
    "#                 st.session_state['search_results'] = search_results\n",
    "\n",
    "#                 # Clean up temporary image\n",
    "#                 if uploaded_image and os.path.exists(image_path):\n",
    "#                     os.remove(image_path)\n",
    "\n",
    "#     # Display search results\n",
    "#     if 'search_results' in st.session_state:\n",
    "#         search_results = st.session_state['search_results']\n",
    "#         st.subheader(\"Search Results:\")\n",
    "#         file_paths = []\n",
    "#         image_paths = []\n",
    "#         video_paths = []\n",
    "\n",
    "#         # Organize results\n",
    "#         for result in search_results['text']:\n",
    "#             if result['path'] not in file_paths:\n",
    "#                 file_paths.append(result['path'])\n",
    "#         for result in search_results['image']:\n",
    "#             if result['file_type'] == 'image' and result['path'] not in image_paths:\n",
    "#                 image_paths.append(result['path'])\n",
    "#             if result['file_type'] == 'video_frame' and result['path'] not in video_paths:\n",
    "#                 video_paths.append(result['path'])\n",
    "\n",
    "#         # Display text files\n",
    "#         for path in file_paths:\n",
    "#             st.write(f\"**Found:** {os.path.basename(path)}\")\n",
    "#             if st.button(f\"Open: {os.path.basename(path)}\", key=f\"open_{path}\"):\n",
    "#                 open_file(path)\n",
    "\n",
    "#         # Display images\n",
    "#         for image_path in image_paths:\n",
    "#             st.image(image_path, caption=os.path.basename(image_path), use_column_width=True)\n",
    "\n",
    "#         # Display videos\n",
    "#         for video_path in video_paths:\n",
    "#             st.video(video_path)\n",
    "\n",
    "# def front_page():\n",
    "#     st.markdown(\"<h1 style='text-align: center;'>Welcome to LocalInsight!</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "#     # Path for the local video\n",
    "#     local_video_path = \"LOCALINSIGHT (2).mp4\"\n",
    "    \n",
    "#     # Check if the video file exists\n",
    "#     if os.path.exists(local_video_path):\n",
    "#         with open(local_video_path, \"rb\") as file:\n",
    "#             video_bytes = file.read()\n",
    "        \n",
    "#         # Video styling (fixed size, centered, and no overflow)\n",
    "#         video_html = f\"\"\"\n",
    "#         <style>\n",
    "#         .video-container {{\n",
    "#             width: 70%;\n",
    "#             height: 400px;  /* Fixed height for the video */\n",
    "#             margin: 20px auto;\n",
    "#             padding: 10px;\n",
    "#             background-color: #000;\n",
    "#             border-radius: 10px;\n",
    "#             box-shadow: 0px 4px 20px rgba(0, 0, 0, 0.3);\n",
    "#             text-align: center;\n",
    "#         }}\n",
    "#         .video-container:hover {{\n",
    "#             transform: scale(1.05);\n",
    "#             box-shadow: 0px 8px 40px rgba(0, 0, 0, 0.6);\n",
    "#         }}\n",
    "        \n",
    "#         video {{\n",
    "#             width: 100%;\n",
    "#             height: 100%;  /* Ensure the video takes up all available space */\n",
    "#             object-fit: cover;\n",
    "#             border-radius: 10px;\n",
    "#         }}\n",
    "\n",
    "#         .stButton > button {{\n",
    "#             display: block;\n",
    "#             margin: 20px auto;\n",
    "#             padding: 12px 30px;\n",
    "#             border-radius: 10px;\n",
    "#             border: none;\n",
    "#             font-size: 16px;\n",
    "#             font-weight: bold;\n",
    "#             cursor: pointer;\n",
    "#             transition: background-color 0.3s ease;\n",
    "#         }}\n",
    "\n",
    "#         .stButton > button:hover {{\n",
    "#             background-color: #FFA500;\n",
    "#         }}\n",
    "#         </style>\n",
    "\n",
    "#         <div class=\"video-container\">\n",
    "#             <video autoplay muted loop playsinline>\n",
    "#                 <source src=\"data:video/mp4;base64,{base64.b64encode(video_bytes).decode()}\" type=\"video/mp4\">\n",
    "#                 Your browser does not support the video tag.\n",
    "#             </video>\n",
    "#         </div>\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Display the video HTML\n",
    "#         st.markdown(video_html, unsafe_allow_html=True)\n",
    "#     else:\n",
    "#         st.error(\"Video file not found. Please check the path.\")\n",
    "    \n",
    "#     # Handle session timing\n",
    "#     if 'start_time' not in st.session_state:\n",
    "#         st.session_state['start_time'] = time.time()\n",
    "#     elapsed_time = time.time() - st.session_state['start_time']\n",
    "    \n",
    "#     if elapsed_time > 5:  \n",
    "#         st.session_state['viewed_front_page'] = True\n",
    "#         st.rerun()\n",
    "\n",
    "#     # Button placed directly below the video (Centered)\n",
    "#     col1, col2, col3 = st.columns([1, 2, 1])  # Center the button\n",
    "#     with col2:\n",
    "#         if st.button(\"Proceed to Login/Signup\"):\n",
    "#             st.session_state['viewed_front_page'] = True\n",
    "#             st.rerun()\n",
    "\n",
    "\n",
    "# # UI for main page\n",
    "# def main_interface():\n",
    "#     st.sidebar.title(\"Options\")\n",
    "#     st.sidebar.button(\"Change Folder Path\", on_click=lambda: st.session_state.update({'change_folder_mode': True}))\n",
    "#     st.sidebar.button(\"Logout\", on_click=logout)\n",
    "#     st.session_state['main_mode'] = st.sidebar.radio(\"Select Mode\", options=[\"Search\", \"Chat\"])\n",
    "#     st.title(\"LocalInsight\")\n",
    "#     st.write(f\"Current Folder: {st.session_state['folder_path']}\")\n",
    "#     if st.session_state['main_mode'] == 'Search':\n",
    "#         st.header(\"Search Mode\")\n",
    "#         handle_search()\n",
    "#     else:\n",
    "#         st.header(\"Chat Mode\")\n",
    "#         handle_chat()\n",
    "\n",
    "# def main():\n",
    "#     st.set_page_config(page_title=\"LocalInsight\", page_icon=\"🔍\", layout=\"wide\")\n",
    "#     if 'viewed_front_page' not in st.session_state:\n",
    "#         st.session_state['viewed_front_page'] = False\n",
    "#     if not st.session_state['viewed_front_page']:\n",
    "#         front_page()\n",
    "#     elif not st.session_state['logged_in']:\n",
    "#         login_signup_interface()\n",
    "#     elif st.session_state['change_folder_mode']:\n",
    "#         set_folder_path()\n",
    "#     else:\n",
    "#         main_interface()\n",
    "\n",
    "# # Running the app\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd06ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=62287) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.1.37:8502\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "2025-05-23 13:20:50.951 Uncaught app execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anushverma/Desktop/lumar/lumar_env/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 121, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "             ^^^^^^\n",
      "  File \"/Users/anushverma/Desktop/lumar/lumar_env/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 645, in code_to_exec\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/anushverma/Desktop/lumar/frontend.py\", line 411, in <module>\n",
      "    main()\n",
      "  File \"/Users/anushverma/Desktop/lumar/frontend.py\", line 407, in main\n",
      "    main_interface()\n",
      "  File \"/Users/anushverma/Desktop/lumar/frontend.py\", line 394, in main_interface\n",
      "    handle_chat()\n",
      "  File \"/Users/anushverma/Desktop/lumar/frontend.py\", line 180, in handle_chat\n",
      "    response = chat_client.get_assistant_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anushverma/Desktop/lumar/chat.py\", line 40, in get_assistant_response\n",
      "    return ollama.chat(self.__model, self.__messages, options={\"temperature\":0})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anushverma/Desktop/lumar/lumar_env/lib/python3.12/site-packages/ollama/_client.py\", line 333, in chat\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/anushverma/Desktop/lumar/lumar_env/lib/python3.12/site-packages/ollama/_client.py\", line 178, in _request\n",
      "    return cls(**self._request_raw(*args, **kwargs).json())\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anushverma/Desktop/lumar/lumar_env/lib/python3.12/site-packages/ollama/_client.py\", line 122, in _request_raw\n",
      "    raise ResponseError(e.response.text, e.response.status_code) from None\n",
      "ollama._types.ResponseError: model \"llama3.2-vision:11b\" not found, try pulling it first (status code: 404)\n"
     ]
    }
   ],
   "source": [
    "!streamlit run frontend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (24.2)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (5.29.4)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (4.13.2)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./lumar_env/lib/python3.12/site-packages (from streamlit) (6.5.1)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.40.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lumar_env/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lumar_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lumar_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lumar_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lumar_env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./lumar_env/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.25.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./lumar_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading narwhals-1.40.0-py3-none-any.whl (357 kB)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-macosx_12_0_arm64.whl (30.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.25.1-cp312-cp312-macosx_11_0_arm64.whl (350 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, toml, smmap, rpds-py, pyarrow, narwhals, MarkupSafe, click, cachetools, blinker, referencing, pandas, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [streamlit]21\u001b[0m [streamlit]g]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 altair-5.5.0 blinker-1.9.0 cachetools-5.5.2 click-8.2.1 gitdb-4.0.12 gitpython-3.1.44 jinja2-3.1.6 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 narwhals-1.40.0 pandas-2.2.3 pyarrow-20.0.0 pydeck-0.9.1 pytz-2025.2 referencing-0.36.2 rpds-py-0.25.1 smmap-5.0.2 streamlit-1.45.1 toml-0.10.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
